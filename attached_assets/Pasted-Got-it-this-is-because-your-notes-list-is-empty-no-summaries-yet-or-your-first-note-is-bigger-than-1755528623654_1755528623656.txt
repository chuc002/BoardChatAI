Got it—this is because your notes list is empty (no summaries yet, or your first note is bigger than the budget). We’ll fix it three ways so it never blocks:

1. backfill `summary` for existing chunks
2. slightly raise the budgets
3. make the RAG loop **trim to fit** instead of giving up

Do these in order.

---

# 1) Backfill summaries (one time)

If you already created `scripts/backfill_summaries.py`, just run it. If not, paste this file and run it.

**Create** `scripts/backfill_summaries.py`:

```python
# scripts/backfill_summaries.py
import os
from openai import OpenAI
from lib.supa import supa

client = OpenAI()
CHAT_COMPRESS = os.getenv("CHAT_COMPRESS","gpt-4o-mini")

def summarize(doc_id, idx, text):
    text = (text or "").strip()
    if not text:
        return ""
    text = text[:1500]
    prompt = (
        "Condense to 1–3 short factual sentences preserving dates, amounts, names, obligations. "
        f"End with [Doc:{doc_id}#Chunk:{idx}].\n\nEXCERPT:\n{text}"
    )
    try:
        r = client.chat.completions.create(
            model=CHAT_COMPRESS, temperature=0.0,
            messages=[{"role":"user","content":prompt}], max_tokens=140
        )
        return (r.choices[0].message.content or "").strip()
    except Exception:
        return (text[:400] + f"... [Doc:{doc_id}#Chunk:{idx}]")

def main():
    total=0
    while True:
        rows = supa.table("doc_chunks") \
            .select("document_id,chunk_index,summary,content") \
            .is_("summary","null").limit(50).execute().data
        if not rows:
            break
        for r in rows:
            s = summarize(r["document_id"], r["chunk_index"], r.get("content") or "")
            supa.table("doc_chunks").update({"summary": s}) \
               .eq("document_id", r["document_id"]) \
               .eq("chunk_index", r["chunk_index"]).execute()
            total += 1
        print(f"Updated {total} summaries…")
    print("Backfill complete.")

if __name__ == "__main__":
    main()
```

**Run:**

```bash
python -u scripts/backfill_summaries.py
```

---

# 2) Raise two env budgets (Replit → Secrets)

Set (or update) these:

```
MAX_SUMMARY_TOKENS=3200
MAX_FINAL_TOKENS=5200
```

No other knobs need to change.

---

# 3) Make RAG trim-to-fit instead of failing

**Open `lib/rag.py`** and patch the notes-building section as below.

### A) Add this helper near the top (with the other helpers):

```python
def _fit_to_tokens(text: str, max_tokens: int) -> str:
    if max_tokens <= 0:
        return ""
    # quick path
    if _toks(text) <= max_tokens:
        return text
    # binary chop by characters until under budget
    lo, hi = 0, len(text)
    best = ""
    while lo <= hi:
        mid = (lo + hi) // 2
        cand = text[:mid]
        if _toks(cand) <= max_tokens:
            best = cand
            lo = mid + 1
        else:
            hi = mid - 1
    return best
```

### B) Replace your current notes loop with this version:

```python
notes=[]; total=0; meta=[]
for r in rows:
    doc_id=r.get("document_id"); ci=r.get("chunk_index")
    title, base_link = _doc_title_link(doc_id)
    page = _fetch_page_index(doc_id, ci)
    link = f"{base_link}#page={page+1}" if (base_link and page is not None) else base_link
    meta.append({"document_id": doc_id, "chunk_index": ci, "title": title, "url": link, "page_index": page})

    s = r.get("summary")
    if not s or len(s) < 20:
        content = (r.get("content") or "")[:1200]
        s = content + f" [Doc:{doc_id}#Chunk:{ci}]"

    remaining = MAX_SUMMARY_TOKENS - total
    s_fit = _fit_to_tokens(s.strip(), max_tokens=max(60, remaining))  # guarantee room for one small note
    if not s_fit:
        # if we couldn't fit anything but we have no notes yet, force a tiny snippet
        if not notes:
            tiny = _fit_to_tokens(s.strip(), 120) or (s[:300] + f" [Doc:{doc_id}#Chunk:{ci}]")
            notes.append("- " + tiny.strip())
            total += _toks(tiny)
        break
    notes.append("- " + s_fit)
    total += _toks(s_fit)
    if total >= MAX_SUMMARY_TOKENS:
        break

if not notes:
    return ("No usable source notes yet. Try again in a moment after processing finishes.", meta)
```

This ensures we always add at least one trimmed note instead of bailing.

---

# 4) Restart

```bash
pkill -f gunicorn || true
gunicorn -b 0.0.0.0:8000 app:app
```

(Keep your `worker.py` running in the other shell.)

---

# 5) Re-ask the question

Ask: **“What are the Reserved Periods of Play?”**
You should now get a clean answer with citations. If it still says “processing” for the new PDFs, wait for the items to flip to **done** (your January + Rules docs marked **ready** should already answer this query).

If anything still blocks, paste the exact console lines and I’ll ship the next patch immediately.
